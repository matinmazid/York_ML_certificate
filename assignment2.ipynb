{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPd9OebbedgbJUryh3TKFm3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matinmazid/York_ML_certificate/blob/master/assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load all the dependant libraries"
      ],
      "metadata": {
        "id": "9ZXkXCB8MvvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scenario 0 No context provided to model"
      ],
      "metadata": {
        "id": "p4mpG5Ve7zpt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5BUlQT1VKP0K",
        "outputId": "0f277966-f877-47fe-b89b-efc5f9e88269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.7/300.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.0/73.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip --quiet install langchain langchain_community pypdf langchain_core langchain-text-splitters langchain-chroma\n",
        "!pip --quiet install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Z0NJOq4NBF_"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the lang chain"
      ],
      "metadata": {
        "id": "Dxu-lUg_UHyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "import langchain_core\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "model = ChatOpenAI(temperature=0, model_name = \"gpt-3.5-turbo\")\n",
        "output_parser = StrOutputParser()\n",
        "chatPrompt=ChatPromptTemplate.from_messages(\n",
        "    [(\"system\",\"you are a financial specialist with experience in Aritifical Intelligence\"),\n",
        "     (\"user\",\"what is XBRL and its relationship to AICPA\")]\n",
        "    )"
      ],
      "metadata": {
        "id": "9V5-5Df1UEFY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain= chatPrompt | model | output_parser"
      ],
      "metadata": {
        "id": "5HDEo4-hUa1I"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "MDYGytCIiZfi",
        "outputId": "70473455-8eea-4f8a-d297-36439677f023"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'XBRL stands for eXtensible Business Reporting Language, which is a standardized format for financial reporting. It allows companies to tag financial data in their reports so that it can be easily analyzed and compared across different organizations. XBRL helps to streamline the process of financial reporting and makes it easier for investors, analysts, and regulators to access and analyze financial information.\\n\\nThe American Institute of Certified Public Accountants (AICPA) is a professional organization for accountants in the United States. The AICPA has been involved in promoting the use of XBRL for financial reporting. They have developed guidelines and best practices for using XBRL in financial reporting to ensure consistency and accuracy in the data being reported.\\n\\nIn summary, the AICPA has a relationship with XBRL in that they support and promote the use of XBRL for financial reporting among their members and the broader accounting community.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scenario 1 Load pdf document loader saving to Chromadb"
      ],
      "metadata": {
        "id": "3itOPpD27ak5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet pypdf\n",
        "!pip install --upgrade --quiet langchain_openai\n",
        "!pip install --quiet tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH4Rs-Tbji3p",
        "outputId": "41eb203c-c2d4-4528-ebc1-ae9235c72d05"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/54.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m1.0/1.2 MB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.stern.nyu.edu/sites/default/files/assets/documents/ChenChoDouLev2021WP.pdf\n",
        "\n",
        "https://python.langchain.com/v0.2/docs/how_to/document_loader_pdf/"
      ],
      "metadata": {
        "id": "cHc6DHAXg7vh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "import tiktoken\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "loader = PyPDFLoader(\"ChenChoDouLev2021WP.pdf\")\n",
        "docs = loader.load()\n",
        "\n",
        "\n",
        "# split and chuck the input data\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=0)\n",
        "# text splitter knows how to extract the text of a sourced doc\n",
        "all_splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# all_texts = [cleanStr(doc.page_content) for doc in all_splits]\n",
        "# all_texts\n",
        "\n",
        "\n",
        "vectorstore = Chroma.from_documents(documents=all_splits,\n",
        "                                    embedding=OpenAIEmbeddings())\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "from langchain import hub\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "rag_chain.invoke(\"what is XBRL and its relationship to AICPA\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "Ss4xJraiBFzd",
        "outputId": "d50e5a83-67a3-49cd-a7b6-ece725bbffec"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"XBRL is the eXtensible Business Reporting Language used for financial reporting. The AICPA is involved in developing data quality tools and working with the FASB on U.S. GAAP taxonomy enhancements related to XBRL. Plumlee and Plumlee (2008) and Boritz and No (2009) discuss the potential challenges of XBRL documents' assurance.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scenario 2 Pine cone database and webcrawler\n",
        "https://python.langchain.com/docs/integrations/document_loaders/recursive_url/\n",
        "https://www150.statcan.gc.ca/n1/daily-quotidien/250207/dq250207a-eng.htm\n"
      ],
      "metadata": {
        "id": "XSPrIYkqo_fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-community beautifulsoup4 lxml"
      ],
      "metadata": {
        "id": "GsQODv-spVrc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "# import html as htmlTool\n",
        "\n",
        "\n",
        "def bs4_extractor(html: str) -> str:\n",
        "    soup = BeautifulSoup(html, \"lxml\")\n",
        "    someText=re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()\n",
        "    # someText=htmlTool.unescape(someText)\n",
        "    # the test page had non-breaking space as well as other non acii characters\n",
        "    # we get rid of them\n",
        "    return someText.encode('latin-1', 'ignore').decode('ascii',\"ignore\")\n"
      ],
      "metadata": {
        "id": "4S8r8Y7duVgS"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import RecursiveUrlLoader\n",
        "\n",
        "loader=RecursiveUrlLoader(url=\"https://www150.statcan.gc.ca/n1/daily-quotidien/250207/dq250207a-eng.htm\",\n",
        "                           use_async=False\n",
        "                          ,extractor=bs4_extractor)\n",
        "\n",
        "docs_html = loader.load()\n",
        "\n",
        "# text splitter knows how to extract the text of a sourced doc\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=0)\n",
        "# text splitter knows how to extract the text of a sourced doc\n",
        "all_splits = text_splitter.split_documents(docs_html)\n"
      ],
      "metadata": {
        "id": "61wtdTFmtGn1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_splits[3]"
      ],
      "metadata": {
        "id": "ocF2mfp1GYVX",
        "outputId": "9d71a678-28e1-4dda-8350-5c7daa8e0b19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'source': 'https://www150.statcan.gc.ca/n1/daily-quotidien/250207/dq250207a-eng.htm', 'content_type': 'text/html; charset=UTF-8', 'title': 'The Daily\\xa0—\\xa0Labour Force Survey, January 2025', 'description': 'Employment increased by 76,000 (+0.4%) in January and the employment rate rose 0.1 percentage points to 61.1%. The unemployment rate declined 0.1 percentage points to 6.6%.', 'language': 'en'}, page_content='527,000\\nJanuary2025\\n\\n-0.1%\\n(monthly change)\\n\\n Source(s): Table 14-10-0287-01.\\r\\n\\n\\r\\nUnemployment rate  N.S.\\r\\n\\n5.9%\\nJanuary2025\\n\\n-0.4pts\\n(monthly change)\\n\\n Source(s): Table 14-10-0287-01.\\r\\n\\nTab1\\nTab2\\n\\n\\r\\nEmployment  N.B.\\r\\n\\n403,000\\nJanuary2025\\n\\n0.7%\\n(monthly change)\\n\\n Source(s): Table 14-10-0287-01.\\r\\n\\n\\r\\nUnemployment rate  N.B.\\r\\n\\n6.4%\\nJanuary2025\\n\\n-1.3pts\\n(monthly change)\\n\\n Source(s): Table 14-10-0287-01.\\r\\n\\nTab1\\nTab2\\n\\n\\r\\nEmployment  Que.\\r\\n\\n4,636,000\\nJanuary2025\\n\\n0.3%\\n(monthly change)')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WtbsukXYGwe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pinecone requires a API key.\n",
        "https://docs.pinecone.io/guides/get-started/quickstart"
      ],
      "metadata": {
        "id": "Hq3Jkg5554aK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet protobuf==3.20.*\n",
        "!pip install  --quiet \"pinecone[grpc]\"\n",
        "!pip install --upgrade --quiet  lark\n",
        "!pip install --upgrade --quiet pinecone-notebooks pinecone-client\n",
        "!pip install --upgrade --quiet langchain_pinecone\n"
      ],
      "metadata": {
        "id": "dRd-r8fs4EsG",
        "outputId": "f21f8e7f-52a5-41fe-8db4-5d3b444babf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "protoc-gen-openapiv2 0.0.1 requires protobuf>=4.21.0, but you have protobuf 3.20.3 which is incompatible.\n",
            "opentelemetry-proto 1.30.0 requires protobuf<6.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.3/427.3 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pinecone-client 5.0.1 requires pinecone-plugin-inference<2.0.0,>=1.0.3, but you have pinecone-plugin-inference 3.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone.grpc import PineconeGRPC as Pinecone\n",
        "from pinecone import ServerlessSpec\n",
        "import time\n",
        "\n"
      ],
      "metadata": {
        "id": "_tHvGn6x6kUa"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "index_name = \"york-1020-assignment-2\"\n",
        "# create new index\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=1536,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "\n",
        "\n",
        "pinecone_vector_store= PineconeVectorStore.from_documents(\n",
        "    documents=all_splits,\n",
        "    embedding=OpenAIEmbeddings(),\n",
        "    index_name=index_name,\n",
        "    text_key=\"page_content\"\n",
        ")\n",
        "\n",
        "pinecone_retriever = pinecone_vector_store.as_retriever()\n",
        "#\n",
        "pinecone_rag_chain = (\n",
        "    {\"context\": pinecone_retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | model\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "Q6RBxpCo_uvz"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone_rag_chain.invoke(\"how much has employment increased\")"
      ],
      "metadata": {
        "id": "_dwD6XdHLdTE",
        "outputId": "4b0bd50f-c9e8-4156-c019-b25db7bddbd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Employment increased by 76,000 in January, with the employment rate rising to 61.1%. The unemployment rate declined to 6.6%. Employment gains were seen across various demographics and industries, with manufacturing and professional services leading the way.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scenario 3 drop box as cloud storage and weaviate"
      ],
      "metadata": {
        "id": "O2lt6r36L6d3"
      }
    }
  ]
}